# ğŸ™ï¸ GPT-OSS Local Voice Agent Demo

> Modern local voice assistant with React frontend and Python backend using Ollama, Whisper, and XTTS

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Node.js 16+](https://img.shields.io/badge/node-16+-green.svg)](https://nodejs.org/)

**Live Demo Features:** Chat Interface â€¢ Voice Mode â€¢ Real-time Processing â€¢ Modern UI â€¢ Completely Local

---

## âœ¨ Features

- ğŸ’¬ **Chat Interface**: Text conversation with local AI models
- ğŸ¤ **Voice Mode**: Speech-to-text with natural voice responses  
- ğŸ”„ **Real-time Status**: Live feedback during processing
- ğŸ¨ **Modern UI**: Beautiful React interface with smooth animations
- ğŸŒ **Completely Local**: No cloud services, full privacy
- ğŸ”§ **Open Source**: Extend and customize as needed

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+** (3.11+ recommended)
- **Node.js 16+** 
- **Ollama** ([Install here](https://ollama.ai))

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/everlastconsulting/gpt-oss-local-voice-agent-demo.git
cd gpt-oss-local-voice-agent-demo

# 2. Backend setup
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# 3. Frontend setup
npm install

# 4. Configure Ollama
ollama pull llama2  # or gpt-oss:20b for German

# 5. Start the application
./start.sh  # Starts both backend and frontend
```

**Access the app at: http://localhost:3000**

## ğŸ¯ Usage

### Chat Mode
1. Type your message and press Enter
2. Get AI responses in real-time

### Voice Mode  
1. Click "Voice Mode" button
2. Click microphone and speak your question
3. Watch real-time transcription
4. Listen to AI voice response

## âš™ï¸ Configuration

Create `.env` file for custom settings:

```env
# Ollama Model
OLLAMA_MODEL=gpt-oss:20b

# Audio Settings
RECORD_DURATION=4
TTS_LANGUAGE=de

# Server
FLASK_RUN_PORT=8080
```

## ğŸ› ï¸ Tech Stack

- **Frontend**: React, Tailwind CSS, Framer Motion
- **Backend**: Flask, Python
- **AI/ML**: Ollama (LLM), Whisper (STT), XTTS (TTS)
- **Audio**: SoundDevice, NumPy, SciPy

## ğŸ¤ Contributing

This is a **demo project** - feel free to:

- ğŸŒŸ **Star** if you find it useful
- ğŸ› **Report issues** you encounter  
- ğŸ’¡ **Suggest features** in discussions
- ğŸ”§ **Submit pull requests** for improvements

### Quick Ideas
- ğŸŒ Add more languages
- ğŸ¨ Improve UI/UX
- ğŸ“± Mobile responsiveness
- âš¡ Performance optimizations

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai) for local LLM hosting
- [OpenAI Whisper](https://openai.com/research/whisper) for speech recognition
- [Coqui TTS](https://github.com/coqui-ai/TTS) for text-to-speech

---

â­ **Star this repo if you like it!** â­

**Built with â¤ï¸ for the open source community**
